{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"synopsis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Comment 0</th>\n",
       "      <td>In the opening, Clint Barton is teaching his d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Comment  Y\n",
       "index                                                          \n",
       "Comment 0  In the opening, Clint Barton is teaching his d...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=[]\n",
    "for i in range(len(df.index)):\n",
    "    index.append(\"Comment \"+str(i))\n",
    "#df.insert(loc=0,column='index',value=index)\n",
    "df['index']=index\n",
    "df.set_index('index', inplace=True)\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(df.Comment.apply(round1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>acquiring</th>\n",
       "      <th>actions</th>\n",
       "      <th>aether</th>\n",
       "      <th>agents</th>\n",
       "      <th>agrees</th>\n",
       "      <th>allies</th>\n",
       "      <th>allow</th>\n",
       "      <th>america</th>\n",
       "      <th>...</th>\n",
       "      <th>wilson</th>\n",
       "      <th>withstand</th>\n",
       "      <th>work</th>\n",
       "      <th>works</th>\n",
       "      <th>workswith</th>\n",
       "      <th>world</th>\n",
       "      <th>worthy</th>\n",
       "      <th>wrestles</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Comment 0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 494 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           able  accidentally  acquiring  actions  aether  agents  agrees  \\\n",
       "index                                                                       \n",
       "Comment 0     1             1          1        1       1       1       2   \n",
       "\n",
       "           allies  allow  america  ...  wilson  withstand  work  works  \\\n",
       "index                              ...                                   \n",
       "Comment 0       1      1        1  ...       2          1     1      1   \n",
       "\n",
       "           workswith  world  worthy  wrestles  years  york  \n",
       "index                                                       \n",
       "Comment 0          1      1       2         1      2     1  \n",
       "\n",
       "[1 rows x 494 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean.Comment)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data_clean.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'able', 1: 'accidentally', 2: 'acquiring', 3: 'actions', 4: 'aether', 5: 'agents', 6: 'agrees', 7: 'allies', 8: 'allow', 9: 'america', 10: 'ancient', 11: 'appears', 12: 'arc', 13: 'archery', 14: 'army', 15: 'arrest', 16: 'artificial', 17: 'asgard', 18: 'assassin', 19: 'assault', 20: 'attacked', 21: 'attempt', 22: 'attempts', 23: 'avengers', 24: 'avoid', 25: 'banner', 26: 'bannerafter', 27: 'barnes', 28: 'barton', 29: 'bartons', 30: 'battle', 31: 'beard', 32: 'begrudgingly', 33: 'best', 34: 'bested', 35: 'blasts', 36: 'board', 37: 'bound', 38: 'brief', 39: 'briefcase', 40: 'bring', 41: 'brought', 42: 'bruce', 43: 'brutally', 44: 'bucky', 45: 'burden', 46: 'captain', 47: 'cardiac', 48: 'carol', 49: 'cartels', 50: 'carter', 51: 'cassie', 52: 'causing', 53: 'chance', 54: 'child', 55: 'circuit', 56: 'clint', 57: 'clints', 58: 'collect', 59: 'concedes', 60: 'concern', 61: 'confirming', 62: 'confirms', 63: 'confiscate', 64: 'conflicted', 65: 'confront', 66: 'consciousness', 67: 'consciousnesses', 68: 'console', 69: 'constructed', 70: 'consumed', 71: 'control', 72: 'conversation', 73: 'convincing', 74: 'counseling', 75: 'counsels', 76: 'craft', 77: 'create', 78: 'custody', 79: 'cuts', 80: 'dance', 81: 'danvers', 82: 'daughter', 83: 'decides', 84: 'defeat', 85: 'defeated', 86: 'defeating', 87: 'destroy', 88: 'destroying', 89: 'devastating', 90: 'devise', 91: 'did', 92: 'die', 93: 'dies', 94: 'difference', 95: 'disappeared', 96: 'discover', 97: 'discovers', 98: 'disguised', 99: 'disintegrates', 100: 'distraught', 101: 'does', 102: 'drops', 103: 'drunk', 104: 'dust', 105: 'dyne', 106: 'earth', 107: 'eating', 108: 'ebony', 109: 'effects', 110: 'efforts', 111: 'elated', 112: 'embark', 113: 'embraced', 114: 'encounter', 115: 'energy', 116: 'enraged', 117: 'entire', 118: 'escape', 119: 'escapes', 120: 'events', 121: 'eventually', 122: 'explain', 123: 'explains', 124: 'exposure', 125: 'fact', 126: 'factors', 127: 'failing', 128: 'fall', 129: 'family', 130: 'farm', 131: 'father', 132: 'fight', 133: 'fighting', 134: 'figure', 135: 'finally', 136: 'finding', 137: 'finds', 138: 'fingers', 139: 'flashback', 140: 'floated', 141: 'following', 142: 'food', 143: 'formulates', 144: 'fortnite', 145: 'foster', 146: 'free', 147: 'friend', 148: 'friends', 149: 'frigga', 150: 'funeral', 151: 'future', 152: 'galaxy', 153: 'gamma', 154: 'gamora', 155: 'gangs', 156: 'gauntlet', 157: 'getting', 158: 'given', 159: 'gives', 160: 'glaive', 161: 'goes', 162: 'got', 163: 'grief', 164: 'guardians', 165: 'guilt', 166: 'hair', 167: 'half', 168: 'hammer', 169: 'hand', 170: 'happened', 171: 'happy', 172: 'head', 173: 'headquarters', 174: 'hearing', 175: 'heart', 176: 'help', 177: 'hes', 178: 'hit', 179: 'hold', 180: 'home', 181: 'hope', 182: 'hours', 183: 'house', 184: 'housing', 185: 'howardrocket', 186: 'hulk', 187: 'hulks', 188: 'hydra', 189: 'ill', 190: 'immediately', 191: 'immense', 192: 'implying', 193: 'impostor', 194: 'improve', 195: 'infinity', 196: 'informed', 197: 'informs', 198: 'initially', 199: 'installation', 200: 'instead', 201: 'intended', 202: 'iron', 203: 'james', 204: 'jane', 205: 'japan', 206: 'joins', 207: 'journey', 208: 'junk', 209: 'kaecilius', 210: 'keeper', 211: 'keeping', 212: 'kidnap', 213: 'kill', 214: 'killed', 215: 'korg', 216: 'lake', 217: 'lands', 218: 'lang', 219: 'langs', 220: 'late', 221: 'later', 222: 'latest', 223: 'launching', 224: 'laws', 225: 'leadership', 226: 'leading', 227: 'learn', 228: 'left', 229: 'lengthy', 230: 'life', 231: 'limited', 232: 'line', 233: 'lines', 234: 'live', 235: 'living', 236: 'loki', 237: 'looking', 238: 'loss', 239: 'love', 240: 'loyal', 241: 'lunch', 242: 'machine', 243: 'make', 244: 'makes', 245: 'malekith', 246: 'malfunctions', 247: 'man', 248: 'maneuvers', 249: 'mantle', 250: 'mark', 251: 'marvel', 252: 'massacring', 253: 'maw', 254: 'maximoff', 255: 'maximoffs', 256: 'meaningful', 257: 'meets', 258: 'melded', 259: 'memories', 260: 'methods', 261: 'miek', 262: 'mind', 263: 'mistakes', 264: 'mjolnor', 265: 'models', 266: 'morag', 267: 'mother', 268: 'multiple', 269: 'nanotech', 270: 'natasha', 271: 'nature', 272: 'nearly', 273: 'nebula', 274: 'nebulas', 275: 'ned', 276: 'nefarious', 277: 'new', 278: 'numerous', 279: 'occur', 280: 'okoye', 281: 'old', 282: 'opening', 283: 'operates', 284: 'operating', 285: 'order', 286: 'orders', 287: 'original', 288: 'overgrown', 289: 'overweight', 290: 'overwhelmed', 291: 'pain', 292: 'parker', 293: 'particles', 294: 'passed', 295: 'passes', 296: 'past', 297: 'paststeve', 298: 'peace', 299: 'peggy', 300: 'pepper', 301: 'peter', 302: 'picnic', 303: 'plan', 304: 'playing', 305: 'population', 306: 'portal', 307: 'potts', 308: 'power', 309: 'prepares', 310: 'presence', 311: 'present', 312: 'prevent', 313: 'preventing', 314: 'process', 315: 'promises', 316: 'proper', 317: 'proposal', 318: 'protection', 319: 'proud', 320: 'pulling', 321: 'purpose', 322: 'purposes', 323: 'pym', 324: 'quantum', 325: 'queen', 326: 'quill', 327: 'radiation', 328: 'radiationfollowing', 329: 'raising', 330: 'reactor', 331: 'reality', 332: 'realizes', 333: 'realm', 334: 'realms', 335: 'reappears', 336: 'reasoning', 337: 'reassemble', 338: 'red', 339: 'reduces', 340: 'reflecting', 341: 'rejects', 342: 'rejoin', 343: 'remaining', 344: 'remains', 345: 'reminded', 346: 'reports', 347: 'rest', 348: 'result', 349: 'retrieve', 350: 'retrieved', 351: 'retrieves', 352: 'return', 353: 'returned', 354: 'returns', 355: 'reunited', 356: 'reverse', 357: 'revived', 358: 'rhodes', 359: 'risking', 360: 'rocket', 361: 'rogers', 362: 'romanoff', 363: 'ronin', 364: 'room', 365: 'royalty', 366: 'rubble', 367: 'running', 368: 'sacrifice', 369: 'sacrificing', 370: 'sam', 371: 'sanctorum', 372: 'sanctum', 373: 'saying', 374: 'scans', 375: 'school', 376: 'scott', 377: 'secluded', 378: 'second', 379: 'self', 380: 'sends', 381: 'sequence', 382: 'sessions', 383: 'set', 384: 'settled', 385: 'sharing', 386: 'shield', 387: 'ship', 388: 'shows', 389: 'sights', 390: 'similar', 391: 'skull', 392: 'small', 393: 'snap', 394: 'snapping', 395: 'solace', 396: 'soon', 397: 'soul', 398: 'space', 399: 'specific', 400: 'spends', 401: 'splitting', 402: 'spy', 403: 'stark', 404: 'starks', 405: 'stating', 406: 'steal', 407: 'stealing', 408: 'steals', 409: 'stephen', 410: 'steve', 411: 'stone', 412: 'stoneafter', 413: 'stones', 414: 'stop', 415: 'stranded', 416: 'strange', 417: 'stranges', 418: 'struggling', 419: 'stumbles', 420: 'succeeds', 421: 'suddenly', 422: 'suit', 423: 'supply', 424: 'survivors', 425: 'systems', 426: 'taking', 427: 'tasked', 428: 'tchalla', 429: 'teaching', 430: 'team', 431: 'teenager', 432: 'tells', 433: 'tesseract', 434: 'test', 435: 'testing', 436: 'thanos', 437: 'thanoss', 438: 'thats', 439: 'theoretical', 440: 'theory', 441: 'thor', 442: 'thors', 443: 'thwarted', 444: 'time', 445: 'tirelessly', 446: 'titan', 447: 'tony', 448: 'town', 449: 'track', 450: 'travel', 451: 'tries', 452: 'triumphantly', 453: 'true', 454: 'truly', 455: 'try', 456: 'tunnel', 457: 'turn', 458: 'ultimately', 459: 'undercover', 460: 'universe', 461: 'use', 462: 'used', 463: 'uses', 464: 'using', 465: 'valkyrie', 466: 'van', 467: 'vanishes', 468: 'vaporized', 469: 'version', 470: 'vials', 471: 'victory', 472: 'vision', 473: 'volunteers', 474: 'vormir', 475: 'wakanda', 476: 'wakandafive', 477: 'wanda', 478: 'warn', 479: 'watch', 480: 'way', 481: 'wield', 482: 'wielding', 483: 'wife', 484: 'wilson', 485: 'withstand', 486: 'work', 487: 'works', 488: 'workswith', 489: 'world', 490: 'worthy', 491: 'wrestles', 492: 'years'}\n"
     ]
    }
   ],
   "source": [
    "id_word_dict={}\n",
    "for i in range(493):\n",
    "    id_word_dict[i]=data_dtm.columns[i]\n",
    "print(id_word_dict)\n",
    "tdm = data_dtm.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 493 is out of bounds for axis 1 with size 493",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f08e5d000391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_word_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreallen\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_no\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meval_every\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m         logger.info(\n\u001b[1;32m    823\u001b[0m             \u001b[0;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bound: at document #%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m                 \u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 493 is out of bounds for axis 1 with size 493"
     ]
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id_word_dict, num_topics=7, passes=100)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
